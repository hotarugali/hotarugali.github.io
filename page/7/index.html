<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>お前はどこまで見えている - 僕たちは そうやって どこまで行くのだろう、どこまで行けるのだろう</title><meta name="author" content="hotarugali"><meta name="copyright" content="hotarugali"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="你的双眼能够看到多远呢">
<meta property="og:type" content="website">
<meta property="og:title" content="お前はどこまで見えている">
<meta property="og:url" content="https://hotarugali.github.io/page/7/index.html">
<meta property="og:site_name" content="お前はどこまで見えている">
<meta property="og:description" content="你的双眼能够看到多远呢">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hotarugali.github.io/img/hotarugali.jpg">
<meta property="article:author" content="hotarugali">
<meta property="article:tag" content="頑張れ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hotarugali.github.io/img/hotarugali.jpg"><link rel="shortcut icon" href="/img/hotarugali.jpg"><link rel="canonical" href="https://hotarugali.github.io/page/7/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?297e40d6e8840f7c1ba9900535589fa1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-FEG5THRHCZ"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-FEG5THRHCZ');
</script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "68ocnze3o7");</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":true,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'お前はどこまで見えている',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-12-17 12:15:20'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_2479343_vob9mc984l.css"><link rel="stylesheet" href="/css/custom.css"  media="defer" onload="this.media='all'"><link rel="stylesheet" href="/css/botui.css"><style type="text/css">.app-refresh{position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease}.app-refresh-wrap{display:flex;color:#fff;height:100%;align-items:center;justify-content:center}.app-refresh-wrap a{color:#fff;text-decoration:underline;cursor:pointer}</style><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-electric-clock-plus@latest/css/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"><link rel="alternate" href="/atom.xml" title="お前はどこまで見えている" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = 'hidden';
    document.getElementById('loading-box').classList.remove("loaded")
  }
}

preloader.initLoading()
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/hotarugali.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">529</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">161</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">155</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw iconfont icon-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw iconfont icon-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw iconfont icon-label"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw iconfont icon-Category"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw iconfont icon-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw iconfont icon-book"></i><span> 说说</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw iconfont icon-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw iconfont icon-love"></i><span> 番剧</span></a></li><li><a class="site-page child" href="/comment/"><i class="fa-fw iconfont icon-message"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw iconfont icon-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/fcircle/"><i class="fa-fw iconfont icon-f-circle"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw iconfont icon-person1"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/cover/%E5%9B%9B%E6%9C%88%E6%98%AF%E4%BD%A0%E7%9A%84%E8%B0%8E%E8%A8%80-2.png')"><nav id="nav"><span id="blog-info"><a href="/" title="お前はどこまで見えている"><span class="site-name">お前はどこまで見えている</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw iconfont icon-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw iconfont icon-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw iconfont icon-label"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw iconfont icon-Category"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw iconfont icon-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw iconfont icon-book"></i><span> 说说</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw iconfont icon-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw iconfont icon-love"></i><span> 番剧</span></a></li><li><a class="site-page child" href="/comment/"><i class="fa-fw iconfont icon-message"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw iconfont icon-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/fcircle/"><i class="fa-fw iconfont icon-f-circle"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw iconfont icon-person1"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">お前はどこまで見えている</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/hotarugali" target="_blank" title="Github"><i class="iconfont icon-github"></i></a><a class="social-icon" href="https://gitee.com/hotarugali" target="_blank" title="Gitee"><i class="iconfont icon-gitee-fill-round"></i></a><a class="social-icon" href="mailto:hotarugali@163.com" target="_blank" title="Email"><i class="iconfont icon-email"></i></a><a class="social-icon" href="/img/social/wechat.png" target="_blank" title="WeChat"><i class="iconfont icon-weixin"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="iconfont icon-rss"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2022/05/13/Technique/PointCloud/%E7%82%B9%E4%BA%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/%E7%82%B9%E4%BA%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/" title="点云相关资料汇总"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/697.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="点云相关资料汇总"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/05/13/Technique/PointCloud/%E7%82%B9%E4%BA%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/%E7%82%B9%E4%BA%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/" title="点云相关资料汇总">点云相关资料汇总</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-05-13T08:29:51.000Z" title="发表于 2022-05-13 16:29:51">2022-05-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Technique/">Technique</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Technique/PointCloud/">PointCloud</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Technique/">Technique</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/PointCloud/">PointCloud</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/05/13/Technique/PointCloud/%E7%82%B9%E4%BA%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/%E7%82%B9%E4%BA%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/#post-comment"><span class="waline-comment-count" id="/2022/05/13/Technique/PointCloud/%E7%82%B9%E4%BA%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/%E7%82%B9%E4%BA%91%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. PCL（Point Cloud Library）
PCL 是一个应用广泛的点云数据处理库，其使用 C++ 语言编写，支持多种操作系统平台。其整体架构图如下：
 

官方网址
官方手册
开源仓库
中文论坛

详细介绍参见博文 PCL(Point Cloud Library)学习指南&amp;资料推荐（2022版）。中文教程可以看朱德海编写的《点云库 PCL 学习教程》或者郭浩编写的《点云库 PCL 从入门到精通》。
2. ROS
ROS（Robot Operating System）是一个用于构建机器人应用的开源软件库，其包含各种开发者工具，从硬件驱动到 SOTA 的算法等。ROS 的基本架构如下图所示：
 

官方网址
官方手册
官方 Wiki
国际社区
创客智造 中文机器人教程

3. Lidar &amp; Radar

一文了解激光雷达(Lidar)工作原理，及雷达（Radar）、点云数据相关技术与应用领域
激光雷达：3D物体检测算法

4. Trimesh
5. Open3D
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/05/13/Research/ActionRecognition/2014-NIPS-Two-Stream%20Convolutional%20Networks%20for%20Action%20Recognition%20in%20Videos/2014-NIPS-Two-Stream%20Convolutional%20Networks%20for%20Action%20Recognition%20in%20Videos/" title="2014-NIPS-Two-Stream Convolutional Networks for Action Recognition in Videos"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/673.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2014-NIPS-Two-Stream Convolutional Networks for Action Recognition in Videos"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/05/13/Research/ActionRecognition/2014-NIPS-Two-Stream%20Convolutional%20Networks%20for%20Action%20Recognition%20in%20Videos/2014-NIPS-Two-Stream%20Convolutional%20Networks%20for%20Action%20Recognition%20in%20Videos/" title="2014-NIPS-Two-Stream Convolutional Networks for Action Recognition in Videos">2014-NIPS-Two-Stream Convolutional Networks for Action Recognition in Videos</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-05-13T04:40:18.000Z" title="发表于 2022-05-13 12:40:18">2022-05-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/ActionRecognition/">ActionRecognition</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/ActionRecognition/">ActionRecognition</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/05/13/Research/ActionRecognition/2014-NIPS-Two-Stream%20Convolutional%20Networks%20for%20Action%20Recognition%20in%20Videos/2014-NIPS-Two-Stream%20Convolutional%20Networks%20for%20Action%20Recognition%20in%20Videos/#post-comment"><span class="waline-comment-count" id="/2022/05/13/Research/ActionRecognition/2014-NIPS-Two-Stream%20Convolutional%20Networks%20for%20Action%20Recognition%20in%20Videos/2014-NIPS-Two-Stream%20Convolutional%20Networks%20for%20Action%20Recognition%20in%20Videos/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 摘要
这篇文章[1]主要研究了如何有效地将深度学习用在动作识别领域。作者提出，这个任务的主要挑战在于如何让神经网络同时捕获到两种信息：一种是 appearance 信息（比如物体的大小、形状等静态信息），另一种是 motion 信息（即物体的运动信息）。这篇文章的主要贡献有三点，第一是提出了一个基于 CNN 的双流网络，它同时结合了时空间信息；第二，作者展示了即使只有少量训练数据，基于 CNN 的神经网络在视频帧的光流信息上进行训练能取得很好的性能；最后，作者展示了双流网络在多任务学习上的潜力，作者在两个数据集上同时训练一个双流骨干网络，相比于使用单一数据集，训练后的网络在两个数据集上都有性能提升。作者在 UCF-101 和 HMDB-51 数据集上进行了实验，效果能和当时的 SOTA 方法（当时还是非深度的方法）性能相当，比之前使用神经网络的方法要好很多。
2. 引言
相比于单张的静态图片，视频数据提供了一种很好的数据增强，因为视频数据天生就包含了物体形变等各种信息。在这篇文章之前也有一篇基于神经网络做视频理解的网络，但其简单粗暴，直接抽取一些关键帧输入到 CNN 网络中，自然 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/05/06/Technique/Compression/Image/%E5%9B%BE%E5%83%8F%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/%E5%9B%BE%E5%83%8F%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/" title="图像扫描方式"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/643.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像扫描方式"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/05/06/Technique/Compression/Image/%E5%9B%BE%E5%83%8F%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/%E5%9B%BE%E5%83%8F%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/" title="图像扫描方式">图像扫描方式</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-05-06T09:53:28.000Z" title="发表于 2022-05-06 17:53:28">2022-05-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Technique/">Technique</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Technique/Compression/">Compression</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Technique/Compression/Image/">Image</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Technique/">Technique</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Compression/">Compression</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Image/">Image</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/05/06/Technique/Compression/Image/%E5%9B%BE%E5%83%8F%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/%E5%9B%BE%E5%83%8F%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/#post-comment"><span class="waline-comment-count" id="/2022/05/06/Technique/Compression/Image/%E5%9B%BE%E5%83%8F%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/%E5%9B%BE%E5%83%8F%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 简介
在处理图像等二维数据时，虽然有直接的二维数据处理方法，但有时因为各种因素，我们还是会将其展开成一维的序列数据来进行处理。这就涉及到如何将二维数据展开成一维数据，本文介绍一些常见的展开方法及其对应的术语。
2. 光栅扫描
光栅扫描（Raster-Scan）是一种最简单的图像扫描方式，其就是逐行进行扫描，如下图所示：
 
3. Zigzag 扫描
Zigzag 扫描（Zigzag Scan）是按照从左上角到右下角的一种曲折扫描方式，JPEG 算法中就使用了这种扫描方式，具体扫描方式如下图所示：
 
4. 蛇形扫描
蛇形扫描（Snake Scan）也称 SSS 形扫描，故名思义，其扫描方式如下：
 
5. 希尔伯特扫描
希尔伯特扫描（Hilbert Scan）来源于数学中的空间填充曲线，即希尔伯特曲线，其具体扫描方式如下：
 

当然，此类基于空间填充曲线的扫描还有很多类型，不仅仅局限于上述形式，比如附录中的皮亚诺曲线。

附录


皮亚诺扫描（Peano Scan）
 


扫描形式合集
 


</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/05/03/Research/Transformer/2021-ICLR-An%20Image%20is%20Worth%2016x16%20Words%EF%BC%9ATransformers%20for%20Image%20Recognition%20at%20Scale/2021-ICLR-An%20Image%20is%20Worth%2016x16%20Words%EF%BC%9ATransformers%20for%20Image%20Recognition%20at%20Scale/" title="2021-ICLR-An Image is Worth 16x16 Words：Transformers for Image Recognition at Scale"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/1411.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2021-ICLR-An Image is Worth 16x16 Words：Transformers for Image Recognition at Scale"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/05/03/Research/Transformer/2021-ICLR-An%20Image%20is%20Worth%2016x16%20Words%EF%BC%9ATransformers%20for%20Image%20Recognition%20at%20Scale/2021-ICLR-An%20Image%20is%20Worth%2016x16%20Words%EF%BC%9ATransformers%20for%20Image%20Recognition%20at%20Scale/" title="2021-ICLR-An Image is Worth 16x16 Words：Transformers for Image Recognition at Scale">2021-ICLR-An Image is Worth 16x16 Words：Transformers for Image Recognition at Scale</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-05-03T12:48:22.000Z" title="发表于 2022-05-03 20:48:22">2022-05-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/Transformer/">Transformer</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/05/03/Research/Transformer/2021-ICLR-An%20Image%20is%20Worth%2016x16%20Words%EF%BC%9ATransformers%20for%20Image%20Recognition%20at%20Scale/2021-ICLR-An%20Image%20is%20Worth%2016x16%20Words%EF%BC%9ATransformers%20for%20Image%20Recognition%20at%20Scale/#post-comment"><span class="waline-comment-count" id="/2022/05/03/Research/Transformer/2021-ICLR-An%20Image%20is%20Worth%2016x16%20Words%EF%BC%9ATransformers%20for%20Image%20Recognition%20at%20Scale/2021-ICLR-An%20Image%20is%20Worth%2016x16%20Words%EF%BC%9ATransformers%20for%20Image%20Recognition%20at%20Scale/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 摘要
这篇文章[1]主要提出如何将 Transformer 用在计算机视学领域（即 ViT, Vision Transformer），用一句话概率就是这篇文章的标题：An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale，即将图像划分成许多 16×1616 \times 1616×16 的 patch，这样每一个 patch 就相当于自然语言中的一个单词，然后将这些 patch 组成一个序列，并使用一个线性层对每个 patch 进行编码（类似于自然语言处理中的词嵌入），最后就可以将编码得到的序列数据直接输入原版的 Transformer 进行训练，而不需要对架构上做任何针对 CV 的改动。作者提出，虽然注 Transformer 早已被提出并在 NLP 领域引发了一阵热潮，但在 CV 领域 CNN 仍然占主导地位。过去一些尝试将注意力机制用在 CV 中的工作，要么是将注意力和 CNN 结合，要么是将注意力机制作为层嵌入一般的 CNN 网络架构（比如 ResNet），而作者提出其实可以完全 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/05/03/Research/Transformer/2022-CVPR-Swin%20Transformer%EF%BC%9AHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows/2022-CVPR-Swin%20Transformer%EF%BC%9AHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows/" title="2022-CVPR-Swin Transformer：Hierarchical Vision Transformer using Shifted Windows"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/1528.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2022-CVPR-Swin Transformer：Hierarchical Vision Transformer using Shifted Windows"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/05/03/Research/Transformer/2022-CVPR-Swin%20Transformer%EF%BC%9AHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows/2022-CVPR-Swin%20Transformer%EF%BC%9AHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows/" title="2022-CVPR-Swin Transformer：Hierarchical Vision Transformer using Shifted Windows">2022-CVPR-Swin Transformer：Hierarchical Vision Transformer using Shifted Windows</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-05-03T12:47:57.000Z" title="发表于 2022-05-03 20:47:57">2022-05-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/Transformer/">Transformer</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/05/03/Research/Transformer/2022-CVPR-Swin%20Transformer%EF%BC%9AHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows/2022-CVPR-Swin%20Transformer%EF%BC%9AHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows/#post-comment"><span class="waline-comment-count" id="/2022/05/03/Research/Transformer/2022-CVPR-Swin%20Transformer%EF%BC%9AHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows/2022-CVPR-Swin%20Transformer%EF%BC%9AHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 摘要
这篇文章[1]主要提出了一种用于 CV 任务的 Swin Transformer，它是一种使用了移动窗口的层级式 ViT。其主要思想就是借鉴于 CNN，作者想让 Transformer 能像 CNN 一样，通过层级式的特征提出从而使得提取出的特征有多尺度的概念。
作者一开始提到，Transformer 的确具有强大的能力，但直接将其用于 CV 任务存在两个问题。一个是图像中物体尺寸的问题，即使是同一个物体，在不同图像中由于拍摄距离的远近而导致物体的尺寸不同；另一个问题是图像分辨率过大时，直接将每个像素作为一个单词序列长度过大（这个问题也是 ViT 主要解决的）。因此，作者提出了层级式的 Swin Transformer，从而能学习到图像的多尺度信息，刷爆了各种 CV 任务的榜单。
2. 引言
过去 CV 领域一直是 CNN 主导，自从 NLP 领域中强大的 Transformer 出现以后，作者就想将其也用到 CV 领域。ViT 已经成功将其用到了 CV 分类任务上，但对其它任务则没有过多的探究。因此，作者在这篇论文中主要想讲的就是，Transformer 确实可以作为骨干 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/05/01/Research/GAN/2014-NIPS-Generative%20Adversarial%20Nets/2014-NIPS-Generative%20Adversarial%20Nets/" title="2014-NIPS-Generative Adversarial Nets"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/490.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2014-NIPS-Generative Adversarial Nets"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/05/01/Research/GAN/2014-NIPS-Generative%20Adversarial%20Nets/2014-NIPS-Generative%20Adversarial%20Nets/" title="2014-NIPS-Generative Adversarial Nets">2014-NIPS-Generative Adversarial Nets</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-05-01T13:37:41.000Z" title="发表于 2022-05-01 21:37:41">2022-05-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/GAN/">GAN</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/GAN/">GAN</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/05/01/Research/GAN/2014-NIPS-Generative%20Adversarial%20Nets/2014-NIPS-Generative%20Adversarial%20Nets/#post-comment"><span class="waline-comment-count" id="/2022/05/01/Research/GAN/2014-NIPS-Generative%20Adversarial%20Nets/2014-NIPS-Generative%20Adversarial%20Nets/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 摘要
这篇文章[1]主要提出了一种新的估计生成模型的方法：即同时训练两个模型 GGG 和 DDD，其中生成模型 GGG 用来捕获数据分布，鉴别模型 DDD 用来估计样本是来自于真实数据还是由生成模型产生的概率（也即尽可能区分开真实样本和 GGG 生成的样本）。训练 GGG 是通过最大化 DDD 犯错的概率来进行优化的，而训练 DDD 则是通过最小化样本分类损失来进行优化的。以博弈论的角度来看，作者提出的这个 GAN 框架相当于就是一个 minimax 双人博弈的游戏。同时，作者证明了，在假定的函数空间中，GAN 框架存在一个唯一的解，使得 GGG 学习到真实的数据分布，从而产生和给定样本一样的样本，DDD 则无法分辨真实样本和 GGG 产生的样本，即对于这个二分类给出的概率总是 12\frac{1}{2}21​。
2. 动机
以往很多工作，都是尝试通过神经网络去直接学习出原始数据分布，比如首先假设数据分布模型，然后通过最大似估计来求得这个模型的具体参数。然而真实数据分布往往都很复杂，很难直接求得真实数据的分布。近些年，以 VAE 为代表的一类方法，退而求其次，直接学习构建一个能拟 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/05/01/Research/Transformer/2017-NIPS-Attention%20Is%20All%20You%20Need/2017-NIPS-Attention%20Is%20All%20You%20Need/" title="2017-NIPS-Attention Is All You Need"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/482.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2017-NIPS-Attention Is All You Need"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/05/01/Research/Transformer/2017-NIPS-Attention%20Is%20All%20You%20Need/2017-NIPS-Attention%20Is%20All%20You%20Need/" title="2017-NIPS-Attention Is All You Need">2017-NIPS-Attention Is All You Need</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-05-01T11:58:31.000Z" title="发表于 2022-05-01 19:58:31">2022-05-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/Transformer/">Transformer</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/05/01/Research/Transformer/2017-NIPS-Attention%20Is%20All%20You%20Need/2017-NIPS-Attention%20Is%20All%20You%20Need/#post-comment"><span class="waline-comment-count" id="/2022/05/01/Research/Transformer/2017-NIPS-Attention%20Is%20All%20You%20Need/2017-NIPS-Attention%20Is%20All%20You%20Need/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 摘要
这篇文章[1]主要提出了一种新的序列转录神经网络结构：Transformer。在主流的序列转录模型中，往往都是使用编码器+解码器并配合注意力机制，Transformer 也是如此。与以前的主流序列转录模型相比，Transformer 完全没有使用 RNN 和 CNN。在两项机器翻译任务上，Transformer 显示出了强大的性能。
2. 动机
RNN 是经典的处理序列数据的模型，然而它在处理较长的序列数据时，需要一步一步计算出每一个预测数据，因此训练较为困难。同时，如果序列较长时，早期的数据可能就被丢弃而无法被使用。为了解决 RNN 的这些问题，作者借鉴了 CNN 和自注意力的想法，提出了 Transformer 架构。
3. 模型
Transformer 的模型架构如下：

其中，N×N\timesN× 表示有 NNN 个相同的块累在一起；⊕\oplus⊕ 表示向量相加。上图左边是编码器，右边是解码器。图中黑色实线一分为多表示将数据张量直接复制多份，进入 Multi-Head Attention 的三条实黑线从右往左依次为 Q,K,VQ, K, VQ,K,V（见下一小节 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/04/30/Research/ImageCompression/VAE/2018-ICLR-Variational%20image%20compression%20with%20a%20scale%20Hyper-prior/2018-ICLR-Variational%20image%20compression%20with%20a%20scale%20Hyper-prior/" title="2018-ICLR-Variational image compression with a scale Hyper-prior"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/146.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2018-ICLR-Variational image compression with a scale Hyper-prior"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/04/30/Research/ImageCompression/VAE/2018-ICLR-Variational%20image%20compression%20with%20a%20scale%20Hyper-prior/2018-ICLR-Variational%20image%20compression%20with%20a%20scale%20Hyper-prior/" title="2018-ICLR-Variational image compression with a scale Hyper-prior">2018-ICLR-Variational image compression with a scale Hyper-prior</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-04-30T06:09:51.000Z" title="发表于 2022-04-30 14:09:51">2022-04-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/ImageCompression/">ImageCompression</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/ImageCompression/VAE/">VAE</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/ImageCompression/">ImageCompression</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/VAE/">VAE</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/04/30/Research/ImageCompression/VAE/2018-ICLR-Variational%20image%20compression%20with%20a%20scale%20Hyper-prior/2018-ICLR-Variational%20image%20compression%20with%20a%20scale%20Hyper-prior/#post-comment"><span class="waline-comment-count" id="/2022/04/30/Research/ImageCompression/VAE/2018-ICLR-Variational%20image%20compression%20with%20a%20scale%20Hyper-prior/2018-ICLR-Variational%20image%20compression%20with%20a%20scale%20Hyper-prior/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 摘要
这篇文章[1]在上一篇文章[2]基础上增加了一个超先验模块，用来有效地捕获隐变量空间的空间依赖信息。这个超先验可以看作是边信息，使用边信息作为先验来辅助压缩在很多标准的图像压缩算法中都广泛使用，但在基于神经网络的压缩算法中还没有得到研究。因此，作者提出了一个超先验模块，和用于压缩的 AutoEncoder 进行联合训练。作者在文章中展示了其提出方法达到了 SOTA 的性能，同时还对比了使用不同的失真度量进行训练对性能的影响。
2. 引言
最近基于深度学习的有损压缩算法在机器学习领域和图像处理领域得到了广泛重视，出现一系列的相关研究工作。这些工作的基本框架和标准的压缩算法类似，即编码时先将图像由像素域变换到隐表示域，然后在隐表示域上进行量化，再使用无损的熵编码进行压缩；解码则是逆过程。
但是在之前的方法中，用来压缩隐表示的熵模型都是将隐表示看作是完成分解开的，即其每个元素看作是各自独立的。在训练时，这些方法都是使用香农交叉熵作为码率损失：
R=Ey^∼m[−log⁡2py^(y^)](1)R=\mathbb{E}_{\hat{\boldsymbol{y}} \sim m}\l ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/04/26/Research/ResNet/2016-CVPR-Deep%20Residual%20Learning%20for%20Image%20Recognition/2016-CVPR-Deep%20Residual%20Learning%20for%20Image%20Recognition/" title="2016-CVPR-Deep Residual Learning for Image Recognition"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/189.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2016-CVPR-Deep Residual Learning for Image Recognition"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/04/26/Research/ResNet/2016-CVPR-Deep%20Residual%20Learning%20for%20Image%20Recognition/2016-CVPR-Deep%20Residual%20Learning%20for%20Image%20Recognition/" title="2016-CVPR-Deep Residual Learning for Image Recognition">2016-CVPR-Deep Residual Learning for Image Recognition</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-04-26T09:49:23.000Z" title="发表于 2022-04-26 17:49:23">2022-04-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/ResNet/">ResNet</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/ResNet/">ResNet</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/04/26/Research/ResNet/2016-CVPR-Deep%20Residual%20Learning%20for%20Image%20Recognition/2016-CVPR-Deep%20Residual%20Learning%20for%20Image%20Recognition/#post-comment"><span class="waline-comment-count" id="/2022/04/26/Research/ResNet/2016-CVPR-Deep%20Residual%20Learning%20for%20Image%20Recognition/2016-CVPR-Deep%20Residual%20Learning%20for%20Image%20Recognition/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 简介
这篇文章[1]主要思想是将 shortcut 用在了神经网络模型中，从而在一定程度上缓解了深度神经网络训不动的问题（即网络深到一定程度反而性能下降）。shortcut 在 202020 年前的神经网络热潮中就被提出来了，作者从新将其用在了深度神经网络中，发现性能很好。
2. 框架
 
3. 实验
 
可以看到，加入 shortcut 后，34 层的网络在训练误差和测试误差上都要小于 18 层的网络；而在没有加入 shortcut 时，34 层的网络的误差是要高于 18 层的网络的。
4. 分析
我们以一个两层的残差网络模型为例，这两层分别用 f,gf, gf,g 表示，输入用 h(x)h(\boldsymbol{x})h(x) 表示（即表示来自浅层头处理后的输出），则加入 shortcut 后，每一层的梯度为：

第一层：∂[f(h(x))+h(x)]∂x=∂f(h(x))∂x+∂h(x)∂x\frac{\partial [f(h(\boldsymbol{x})) + h(\boldsymbol{x})]}{\partial \boldsymbol{x}} = \frac{ ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/04/26/Research/Sundry/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/" title="神经网络相关指标"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/228.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="神经网络相关指标"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/04/26/Research/Sundry/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/" title="神经网络相关指标">神经网络相关指标</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-04-26T08:48:13.000Z" title="发表于 2022-04-26 16:48:13">2022-04-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/Assessory/">Assessory</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Assessory/">Assessory</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/04/26/Research/Sundry/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/#post-comment"><span class="waline-comment-count" id="/2022/04/26/Research/Sundry/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">在神经网络中，假设：

卷积层的大小用 kh×kw×kckh \times kw \times kckh×kw×kc 表示；




指标
计算公式




FLOPs
(卷积核高×\times×卷积)



</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/04/25/Research/Multimodal/CLIP/2021-Arxiv-Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/2021-Arxiv-Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/" title="2021-Arxiv-Learning Transferable Visual Models From Natural Language Supervision"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/625.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2021-Arxiv-Learning Transferable Visual Models From Natural Language Supervision"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/04/25/Research/Multimodal/CLIP/2021-Arxiv-Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/2021-Arxiv-Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/" title="2021-Arxiv-Learning Transferable Visual Models From Natural Language Supervision">2021-Arxiv-Learning Transferable Visual Models From Natural Language Supervision</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-04-25T11:52:56.000Z" title="发表于 2022-04-25 19:52:56">2022-04-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Research/">Research</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/Multimodal/">Multimodal</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Research/Multimodal/CLIP/">CLIP</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Research/">Research</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/Multimodal/">Multimodal</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/CLIP/">CLIP</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/04/25/Research/Multimodal/CLIP/2021-Arxiv-Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/2021-Arxiv-Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/#post-comment"><span class="waline-comment-count" id="/2022/04/25/Research/Multimodal/CLIP/2021-Arxiv-Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/2021-Arxiv-Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 简介
这篇文章[1]的主要想法是，对自然语言特征和图像特征进行对比学习，训练得到对应的文本和图像编码器，然后使用预训练好的成对的编码器去做各种各样的下游任务。以图像分类任务为例：


在训练阶段，对每个图像的类别按照一种文本范式来构建该图片的描述句子，然后使用一个图像编码器模块和文本编码器模块，分别对图像和文本进行编码得到对应的特征。所有文本特征构成一个文本特征向量，一个 Batch 内的图像特征构成一个图像特征向量，通过计算这两个特征向量间的余弦相似性得到余弦相似矩阵。由于两个向量中的元素是一一对应的，因此在余弦相似矩阵对角线上的图像文本对被看作是正样本，故 Label 就是 [1,⋯ ,n]⊤[1, \cdots, n]^\top[1,⋯,n]⊤，其中 nnn 是矩阵大小，将其与余弦相似矩阵求交叉熵损失即可反传优化图像编码器和文本编码器。


在推理阶段，使用需要分类的类别对应的文本句子作为文本编码器的输入，需要分类的图片作为图像编码器的输入，然后计算二者之间的余弦相似度，选出分类概率最大的那个文本句子，然后提取出句子中包含的类别即可。


通过对文本和图像做对比学习的方式， ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/04/24/Technique/StatisticalLearning/%E6%84%9F%E7%9F%A5%E6%9C%BA/%E6%84%9F%E7%9F%A5%E6%9C%BA/" title="感知机"><img class="post-bg" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/1532.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="感知机"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/04/24/Technique/StatisticalLearning/%E6%84%9F%E7%9F%A5%E6%9C%BA/%E6%84%9F%E7%9F%A5%E6%9C%BA/" title="感知机">感知机</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-04-24T05:14:56.000Z" title="发表于 2022-04-24 13:14:56">2022-04-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Technique/">Technique</a><i class="fas fa-angle-right article-meta-link"></i><a class="article-meta__categories" href="/categories/Technique/StatisticalLearning/">StatisticalLearning</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Technique/">Technique</a><span class="article-meta-link">•</span><a class="article-meta__tags" href="/tags/StatisticalLearning/">StatisticalLearning</a></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-comments"></i><a href="/2022/04/24/Technique/StatisticalLearning/%E6%84%9F%E7%9F%A5%E6%9C%BA/%E6%84%9F%E7%9F%A5%E6%9C%BA/#post-comment"><span class="waline-comment-count" id="/2022/04/24/Technique/StatisticalLearning/%E6%84%9F%E7%9F%A5%E6%9C%BA/%E6%84%9F%E7%9F%A5%E6%9C%BA/"><i class="fa-solid fa-spinner fa-spin"></i></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">1. 简介
感知机是二类分类的线性分类模型，属于监督学习中的判别模型：

输入：实例的特征向量；
输出：实例的类别，取 +1+1+1 和 −1-1−1 值。

感知机本质可以看作是输入空间（特征空间）中将实例划分为正负两类的分离超平面。其基于误分类的损失函数，并利用梯度下降法对损失函数进行极小化进行求解。
2. 模型

定义：假设输入空间（特征空间）是 X⊆Rn\mathcal{X} \subseteq \mathbf{R}^nX⊆Rn，输出空间是要 Y={+1,−1}\mathcal{Y} = \{+1, -1\}Y={+1,−1}。输入 x∈X\boldsymbol{x} \in \mathcal{X}x∈X 表示实例的特征向量，对应于输入空间的点；输出 y∈Yy \in \mathcal{Y}y∈Y 表示实例的类别。由输入空间到输出空间的如下函数f(x)=sign(w⊤x+b)(1)f(\boldsymbol{x}) = \mathrm{sign}(\boldsymbol{w}^\top \boldsymbol{x} + b) \tag{1}
f(x)=sign(w⊤x+b)(1 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/6/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/#content-inner">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/#content-inner">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/45/#content-inner">45</a><a class="extend next" rel="next" href="/page/8/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/hotarugali.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">hotarugali</div><div class="author-info__description">你的双眼能够看到多远呢</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">529</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">161</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">155</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/hotarugali"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/hotarugali" target="_blank" title="Github"><i class="iconfont icon-github"></i></a><a class="social-icon" href="https://gitee.com/hotarugali" target="_blank" title="Gitee"><i class="iconfont icon-gitee-fill-round"></i></a><a class="social-icon" href="mailto:hotarugali@163.com" target="_blank" title="Email"><i class="iconfont icon-email"></i></a><a class="social-icon" href="/img/social/wechat.png" target="_blank" title="WeChat"><i class="iconfont icon-weixin"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="iconfont icon-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客星球 ^_^</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/11/13/Life/%E9%98%85%E8%AF%BB/%E8%A2%AB%E8%AE%A8%E5%8E%8C%E7%9A%84%E5%8B%87%E6%B0%94/" title="被讨厌的勇气"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/1384.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="被讨厌的勇气"/></a><div class="content"><a class="title" href="/2023/11/13/Life/%E9%98%85%E8%AF%BB/%E8%A2%AB%E8%AE%A8%E5%8E%8C%E7%9A%84%E5%8B%87%E6%B0%94/" title="被讨厌的勇气">被讨厌的勇气</a><time datetime="2023-11-13T06:29:28.000Z" title="发表于 2023-11-13 14:29:28">2023-11-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/28/Finance/Quant/%E9%87%8F%E5%8C%96%E7%AC%94%E8%AF%95%E6%95%B0%E7%90%86%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/" title="量化笔试数理知识复习"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/296.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="量化笔试数理知识复习"/></a><div class="content"><a class="title" href="/2023/10/28/Finance/Quant/%E9%87%8F%E5%8C%96%E7%AC%94%E8%AF%95%E6%95%B0%E7%90%86%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0/" title="量化笔试数理知识复习">量化笔试数理知识复习</a><time datetime="2023-10-28T12:33:43.000Z" title="发表于 2023-10-28 20:33:43">2023-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/12/Life/%E9%98%85%E8%AF%BB/%E4%BD%A0%E5%BD%93%E5%83%8F%E9%B8%9F%E9%A3%9E%E5%BE%80%E4%BD%A0%E7%9A%84%E5%B1%B1/" title="你当像鸟飞往你的山"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/1484.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="你当像鸟飞往你的山"/></a><div class="content"><a class="title" href="/2023/10/12/Life/%E9%98%85%E8%AF%BB/%E4%BD%A0%E5%BD%93%E5%83%8F%E9%B8%9F%E9%A3%9E%E5%BE%80%E4%BD%A0%E7%9A%84%E5%B1%B1/" title="你当像鸟飞往你的山">你当像鸟飞往你的山</a><time datetime="2023-10-12T08:36:34.000Z" title="发表于 2023-10-12 16:36:34">2023-10-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/09/Technique/Python/Python%E6%A8%A1%E5%9D%97logging/" title="Python模块logging"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/1130.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python模块logging"/></a><div class="content"><a class="title" href="/2023/10/09/Technique/Python/Python%E6%A8%A1%E5%9D%97logging/" title="Python模块logging">Python模块logging</a><time datetime="2023-10-09T02:04:21.000Z" title="发表于 2023-10-09 10:04:21">2023-10-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/05/Life/%E9%98%85%E8%AF%BB/%E5%A4%B1%E5%8E%BB%E7%9A%84%E4%BA%8C%E5%8D%81%E5%B9%B4%EF%BC%9A%E6%97%A5%E6%9C%AC%E7%BB%8F%E6%B5%8E%E9%95%BF%E6%9C%9F%E5%81%9C%E6%BB%9E%E7%9A%84%E7%9C%9F%E6%AD%A3%E5%8E%9F%E5%9B%A0/" title="失去的二十年：日本经济长期停滞的真正原因"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://hotarugali.github.io/FigureBed/wallpaper/240.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="失去的二十年：日本经济长期停滞的真正原因"/></a><div class="content"><a class="title" href="/2023/10/05/Life/%E9%98%85%E8%AF%BB/%E5%A4%B1%E5%8E%BB%E7%9A%84%E4%BA%8C%E5%8D%81%E5%B9%B4%EF%BC%9A%E6%97%A5%E6%9C%AC%E7%BB%8F%E6%B5%8E%E9%95%BF%E6%9C%9F%E5%81%9C%E6%BB%9E%E7%9A%84%E7%9C%9F%E6%AD%A3%E5%8E%9F%E5%9B%A0/" title="失去的二十年：日本经济长期停滞的真正原因">失去的二十年：日本经济长期停滞的真正原因</a><time datetime="2023-10-05T11:17:34.000Z" title="发表于 2023-10-05 19:17:34">2023-10-05</time></div></div></div></div><div class="card-widget" id="card-newest-comments"><div class="item-headline"><i class="fas fa-comment-dots"></i><span>最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Language/" style="font-size: 1.19em; color: rgb(166, 45, 103)">Language</a><a href="/tags/Japanese/" style="font-size: 1.19em; color: rgb(197, 150, 4)">Japanese</a><a href="/tags/Finance/" style="font-size: 1.21em; color: rgb(162, 104, 144)">Finance</a><a href="/tags/Quant/" style="font-size: 1.19em; color: rgb(50, 14, 145)">Quant</a><a href="/tags/Share/" style="font-size: 1.15em; color: rgb(61, 168, 17)">Share</a><a href="/tags/Game/" style="font-size: 1.19em; color: rgb(155, 101, 48)">Game</a><a href="/tags/MonsterHunter/" style="font-size: 1.15em; color: rgb(15, 10, 68)">MonsterHunter</a><a href="/tags/PSP/" style="font-size: 1.15em; color: rgb(24, 57, 121)">PSP</a><a href="/tags/Tools/" style="font-size: 1.31em; color: rgb(104, 85, 195)">Tools</a><a href="/tags/Life/" style="font-size: 1.35em; color: rgb(149, 100, 60)">Life</a><a href="/tags/%E7%94%9F%E4%BA%A7%E5%8A%9B/" style="font-size: 1.17em; color: rgb(96, 60, 102)">生产力</a><a href="/tags/%E8%AF%BE%E7%A8%8B/" style="font-size: 1.15em; color: rgb(30, 186, 131)">课程</a><a href="/tags/%E9%98%85%E8%AF%BB/" style="font-size: 1.21em; color: rgb(35, 168, 103)">阅读</a><a href="/tags/%E9%9F%B3%E4%B9%90/" style="font-size: 1.15em; color: rgb(85, 180, 105)">音乐</a><a href="/tags/Literature/" style="font-size: 1.19em; color: rgb(157, 157, 144)">Literature</a><a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 1.15em; color: rgb(93, 67, 56)">工具</a><a href="/tags/%E6%91%98%E5%BD%95/" style="font-size: 1.17em; color: rgb(173, 188, 194)">摘录</a><a href="/tags/Research/" style="font-size: 1.41em; color: rgb(7, 153, 147)">Research</a><a href="/tags/PaperReading/" style="font-size: 1.17em; color: rgb(180, 71, 42)">PaperReading</a><a href="/tags/Sundry/" style="font-size: 1.43em; color: rgb(83, 88, 113)">Sundry</a><a href="/tags/Assessory/" style="font-size: 1.27em; color: rgb(57, 189, 32)">Assessory</a><a href="/tags/Technique/" style="font-size: 1.45em; color: rgb(130, 18, 78)">Technique</a><a href="/tags/Browser/" style="font-size: 1.17em; color: rgb(113, 22, 27)">Browser</a><a href="/tags/C/" style="font-size: 1.29em; color: rgb(67, 29, 77)">C++</a><a href="/tags/CMake/" style="font-size: 1.17em; color: rgb(91, 113, 150)">CMake</a><a href="/tags/ChannelCoding/" style="font-size: 1.23em; color: rgb(179, 190, 127)">ChannelCoding</a><a href="/tags/Configure/" style="font-size: 1.15em; color: rgb(130, 59, 65)">Configure</a><a href="/tags/CryptographyBasics/" style="font-size: 1.33em; color: rgb(138, 185, 116)">CryptographyBasics</a><a href="/tags/DIP/" style="font-size: 1.17em; color: rgb(64, 38, 177)">DIP</a><a href="/tags/DeepLearning/" style="font-size: 1.39em; color: rgb(78, 63, 68)">DeepLearning</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.37em; color: rgb(158, 5, 111)">深度学习</a><a href="/tags/Docker/" style="font-size: 1.15em; color: rgb(144, 43, 125)">Docker</a><a href="/tags/GPS/" style="font-size: 1.15em; color: rgb(152, 150, 118)">GPS</a><a href="/tags/Git/" style="font-size: 1.21em; color: rgb(188, 103, 181)">Git</a><a href="/tags/Go/" style="font-size: 1.23em; color: rgb(37, 163, 181)">Go</a><a href="/tags/Hexo/" style="font-size: 1.15em; color: rgb(94, 128, 21)">Hexo</a><a href="/tags/ImageMoment/" style="font-size: 1.15em; color: rgb(197, 134, 11)">ImageMoment</a><a href="/tags/InformationTheory/" style="font-size: 1.19em; color: rgb(40, 179, 134)">InformationTheory</a><a href="/tags/InputMethod/" style="font-size: 1.21em; color: rgb(46, 53, 40)">InputMethod</a><a href="/tags/JavaScript/" style="font-size: 1.25em; color: rgb(31, 67, 60)">JavaScript</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">十一月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">十月 2023</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">九月 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">八月 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">七月 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">六月 2023</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">五月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">三月 2023</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">529</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2021-04-07T19:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">560.6k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-12-17T04:15:13.320Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div><div class="card-widget user-map"><div class="item-headline"><i class="fas fa-heartbeat"></i><span>访客地图</span></div><div class="item-content"><script data-pjax type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=j7b3NOw-siuyxSK5-pubSVIOWKk8AMrKcwIBbIAP32A"></script></div></div></div></div></main><footer id="footer" style="background-image: url('/img/cover/%E5%9B%9B%E6%9C%88%E6%98%AF%E4%BD%A0%E7%9A%84%E8%B0%8E%E8%A8%80-2.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By hotarugali</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, Welcome to my blog.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  function loadWaline () {
    function initWaline () {
      let initData = {
        el: null,
        serverURL: 'https://waline-v2-hotarugali.vercel.app',
        comment: true
      }
      const waline = Waline.init(initData)
    }

    if (typeof Waline === 'object') initWaline() 
    else getScript('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js').then(initWaline)
  }

  window.pjax ? loadWaline() : window.addEventListener('load', loadWaline)
})()</script><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["僕たちは そうやって どこまで行くのだろう、どこまで行けるのだろう"])
  } else {
    document.getElementById("subtitle").textContent = '僕たちは そうやって どこまで行くのだろう、どこまで行けるのだろう'
  }
}
typedJSFn.run(subtitleType)</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    btf.addModeChange('mermaid', () => {
      window.runMermaid()
    })

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const loadWaline = () => {
      Waline.RecentComments({
        serverURL: 'https://waline-v2-hotarugali.vercel.app',
        count: 6
      }).then(({comments}) => {
        const walineArray = comments.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.insertedAt,
          }
        })
        saveToLocal.set('waline-newest-comments', JSON.stringify(walineArray), 10/(60*24))
        generateHtml(walineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      }) 
    }

    if (typeof Waline === 'object') loadWaline()
    else getScript('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js').then(loadWaline)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('waline-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><div class="aplayer no-destroy" data-id="3107777185" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="auto" data-autoplay="false" muted></div><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><script defer src="/live2d-widget/autoload.js"></script><div class="app-refresh" id="app-refresh"> <div class="app-refresh-wrap"> <label>✨ 網站已更新最新版本 👉</label> <a href="javascript:void(0)" onclick="location.reload()">點擊刷新</a> </div></div><script>function showNotification(){if(GLOBAL_CONFIG.Snackbar){var t="light"===document.documentElement.getAttribute("data-theme")?GLOBAL_CONFIG.Snackbar.bgLight:GLOBAL_CONFIG.Snackbar.bgDark,e=GLOBAL_CONFIG.Snackbar.position;Snackbar.show({text:"已更新最新版本",backgroundColor:t,duration:5e5,pos:e,actionText:"點擊刷新",actionTextColor:"#fff",onActionClick:function(t){location.reload()}})}else{var o=`top: 0; background: ${"light"===document.documentElement.getAttribute("data-theme")?"#49b1f5":"#1f1f1f"};`;document.getElementById("app-refresh").style.cssText=o}}"serviceWorker"in navigator&&(navigator.serviceWorker.controller&&navigator.serviceWorker.addEventListener("controllerchange",function(){showNotification()}),window.addEventListener("load",function(){navigator.serviceWorker.register("/sw.js")}));</script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="//code.tidio.co/p6xsdfucuppqybcfijot1hsnancsqec5.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start -->
  <script data-pjax src="/js/githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api-hotarugali.vercel.app/api?hotarugali";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="hotarugali";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function history_calendar_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height: 100px;overflow: hidden"><div class="history_swiper-container" id="history-container" style="width: 100%;height: 100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div>';
                console.log('已挂载history_calendar')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='/'|| '/' ==='all')){

            history_calendar_injector_config()
        } </script><script data-pjax  src="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.js"></script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/npm/hexo-electric-clock-plus@latest/images/weather/loading.gif" style="height: 136px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='/'|| '/' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script type="text/javascript">var font='UnidreamLED'</script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script>
        <script type="text/javascript">
            loc = $.ajax({
                    url: "https://ipapi.co/json/",  //json文件位置，文件名
                    type: "GET",                    //请求方式为get
                    dataType: "json",               //返回数据格式为json
                    async: false,
                    success: function(data) {       //请求成功完成后要执行的方法 
                    }
                });
            ip=$.parseJSON(loc.responseText).ip;
            version=$.parseJSON(loc.responseText).version;
            city=$.parseJSON(loc.responseText).city;
            country=$.parseJSON(loc.responseText).country_name;
        </script>
        <script data-pjax src="https://cdn.jsdelivr.net/npm/hexo-electric-clock-plus@latest/js/clock.js"></script><!-- hexo injector body_end end --><script src="/js/markmap.js"></script></body></html>